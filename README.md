# Distributed Log Processing System

## Project Overview

We're building a distributed system for processing log data at scale. This repository contains all the code and configuration needed to run the system.

## Getting Started

### Prerequisites

- Docker and Docker Compose
- Git
- VS Code (recommended)

### Running the Application

1. Clone this repository
2. Navigate to the project directory
3. Run `docker-compose up --build`

## Project Structure

- `src/services/`: Contains individual microservices
- `config/`: Configuration files
- `data/`: Data storage (gitignored)
- `docs/`: Documentation
- `tests/`: Test suites

---

## ğŸ”§ Features

### âœ… Logger Service

- Logs service heartbeat messages at a configurable frequency
- Logs are written to **both console and rotating file**
- Uses Pythonâ€™s `logging` module with log level and format controls

### âœ… Log Rotation

- Logs are saved to `logs/app.log`
- When file exceeds **1MB**, it rotates (keeps up to 3 backups)

---

## âš™ï¸ Configuration Options

You can configure the logger via environment variables in `docker-compose.yml`:

| Variable        | Description                             | Default           |
| --------------- | --------------------------------------- | ----------------- |
| `LOG_LEVEL`     | Logging level (`DEBUG`, `INFO`, etc.)   | `INFO`            |
| `LOG_FREQUENCY` | How often logs are emitted (in seconds) | `5`               |
| `LOG_FORMAT`    | Format string for logs                  | See default below |
| `LOG_FILE`      | Path to log file                        | `logs/app.log`    |

**Example format string:**

```
[%(asctime)s] %(levelname)s: %(message)s
```

You can adjust these values in the `environment:` section of your `docker-compose.yml`.

---

## ğŸš€ Development Milestones

### Day 1 Milestones

- Set up development environment
- Created project structure
- Implemented basic logger service
- ğŸ”„ Added log file output with rotation
- ğŸŒ Added web interface to view logs and config
- ğŸ›  Documented configuration and endpoints

### Day 2 Milestones

- âœ… Enhanced log generator with custom fields (e.g., user ID, session token)
- ğŸ”„ Supported multiple output formats: JSON, CSV, and plain text
- âš¡ Introduced burst mode to simulate spikes in log activity
- ğŸ” Refined log patterns to reflect realistic event flows and timing
- ğŸ“„ Updated documentation for log schema and usage examples

### Day 3 Milestones

- ğŸ‘ï¸â€ğŸ—¨ï¸ Built a real-time log collector using file watchers
- ğŸ§  Supported multiple log formats (JSON and plain text) with dynamic parsing
- ğŸ” Added regex-based filtering for log entry matching
- ğŸ·ï¸ Implemented tagging system to categorize entries (e.g., `auth`, `payment`, `api`)
- âš ï¸ Tracked and reported parsing errors for malformed log lines
- ğŸ’¾ Persisted structured collected entries to `collected_logs/collected.jsonl`
- ğŸ›  Updated Docker Compose to pass collector configuration via CLI arguments
